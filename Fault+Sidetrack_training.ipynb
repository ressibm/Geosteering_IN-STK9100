{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71893582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from DDQN_Agent import DDQNAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3eaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Geosteering_gym import Geosteering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64855bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(runs, bd, val, lookahead, gamma, writer):\n",
    "    if __name__ == '__main__':\n",
    "        start = time.time()\n",
    "        env = Geosteering(render_=True,eval=False)\n",
    "        n_games = runs\n",
    "        gamma = gamma\n",
    "        eps_min = 0.01\n",
    "        eps_dec = 0.9995\n",
    "\n",
    "        writer_stat = writer\n",
    "        if writer_stat:\n",
    "            writer = SummaryWriter(comment=\"_BD=%s_Val=%s_v1\"%(bd,val))\n",
    "\n",
    "        scores = np.zeros([n_games])\n",
    "        avg_score = np.zeros([n_games])\n",
    "        states = (2*(env.look_ahead)+8,)\n",
    "        bd_actions = 2*env.bd_step + 2\n",
    "        \n",
    "        bd_agent = DDQNAgent(gamma=gamma, lr=0.0005, n_actions=bd_actions, n_states=states,\n",
    "                    batch_size=32, mem_size=25000, replace=1000, \n",
    "                    saved_dir='trained network/',\n",
    "                    env_name='Geosteering_bitdepth_BD=%s_Val=%s_LookAhead=%s_GYM1'%(bd,val,lookahead))\n",
    "        \n",
    "        best_score = -np.inf\n",
    "        result = cv2.VideoWriter('Training.mp4', \n",
    "                 cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "                 5, (1280,720))\n",
    "        add = 0 \n",
    "        for i in tqdm(range(n_games)):\n",
    "            done = False\n",
    "            observation = env.reset()\n",
    "            score = 0\n",
    "            if i%2000 == 0:\n",
    "                env.render_ = True\n",
    "            while not done:\n",
    "                action = bd_agent.choose_action(observation)\n",
    "                if env.exit == 0 and action == env.bd_step*2+1:\n",
    "                    action = env.bd_step\n",
    "                observation_, reward, done, info = env.step(action)\n",
    "\n",
    "                if i in np.arange(0,2)+add:\n",
    "                    result.write(env.canvas)\n",
    "                score += reward\n",
    "                bd_agent.store_transition(observation, action,\n",
    "                                           reward, observation_, done)\n",
    "                bd_agent.learn()\n",
    "\n",
    "                if writer_stat and bd_agent.learn_idx%5000==4999:\n",
    "                    loss_plot = bd_agent.running_loss/5000\n",
    "                    bd_agent.running_loss = 0\n",
    "                    writer.add_scalar(\"loss\", loss_plot, bd_agent.learn_idx)\n",
    "                observation = observation_\n",
    "            if i == max(np.arange(0,2)+add):\n",
    "                add += 2000\n",
    "                env.render_ = False\n",
    "\n",
    "            bd_agent.epsilon = bd_agent.epsilon*eps_dec \\\n",
    "            if bd_agent.epsilon > eps_min else eps_min\n",
    "\n",
    "            scores[i] = score\n",
    "            if i>= 100:\n",
    "                avg_score[i] = np.mean(scores[i-99:i+1])\n",
    "                \n",
    "            if avg_score[i] > best_score and i>= 100:\n",
    "                bd_agent.save_models()\n",
    "                best_score = avg_score[i]\n",
    "                      \n",
    "            if writer_stat:\n",
    "                writer.add_scalar(\"reward_100\", avg_score[i], i)\n",
    "                writer.add_scalar(\"reward\", scores[i], i)\n",
    "                \n",
    "\n",
    "        end = time.time()\n",
    "        elapsed_time = (end-start)\n",
    "        start = end\n",
    "        print('======== Finished with elapsed time of %.2f' %elapsed_time, 'seconds ========')\n",
    "        if writer_stat:\n",
    "            writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in [2]:\n",
    "    for bd in [2]:\n",
    "        train_func(runs= 10000, bd=bd, val= val, lookahead= 1, gamma= 0.99, writer=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
